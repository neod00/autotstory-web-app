#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
URL ìœ íš¨ì„± ê²€ì‚¬ ë° ë¯¸ë¦¬ë³´ê¸° ëª¨ë“ˆ
================================

URL ì½˜í…ì¸  ì¶”ì¶œ ì „ì— URLì˜ ìœ íš¨ì„±ì„ ê²€ì‚¬í•˜ê³ 
ë¯¸ë¦¬ë³´ê¸° ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ëª¨ë“ˆ
"""

import re
import requests
from urllib.parse import urlparse
from bs4 import BeautifulSoup
import time

class URLValidator:
    """URL ìœ íš¨ì„± ê²€ì‚¬ ë° ë¯¸ë¦¬ë³´ê¸° í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        })
    
    def validate_url(self, url):
        """
        URL ìœ íš¨ì„± ê²€ì‚¬
        
        Args:
            url (str): ê²€ì‚¬í•  URL
            
        Returns:
            dict: ê²€ì‚¬ ê²°ê³¼ ì •ë³´
        """
        result = {
            'valid': False,
            'accessible': False,
            'type': 'unknown',
            'title': '',
            'description': '',
            'error': ''
        }
        
        try:
            # 1. URL í˜•ì‹ ê²€ì‚¬
            if not self._is_valid_url_format(url):
                result['error'] = 'URL í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.'
                return result
            
            result['valid'] = True
            
            # 2. URL íƒ€ì… ê°ì§€
            result['type'] = self._detect_url_type(url)
            
            # 3. ì ‘ê·¼ì„± í™•ì¸
            response = self.session.head(url, timeout=10, allow_redirects=True)
            if response.status_code in [200, 301, 302]:
                result['accessible'] = True
                
                # 4. ë¯¸ë¦¬ë³´ê¸° ì •ë³´ ì¶”ì¶œ
                preview_info = self._get_preview_info(url)
                result.update(preview_info)
            else:
                result['error'] = f'HTTP ì˜¤ë¥˜: {response.status_code}'
                
        except requests.exceptions.RequestException as e:
            result['error'] = f'ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜: {str(e)}'
        except Exception as e:
            result['error'] = f'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜: {str(e)}'
            
        return result
    
    def _is_valid_url_format(self, url):
        """URL í˜•ì‹ ê²€ì‚¬"""
        try:
            parsed = urlparse(url)
            return bool(parsed.netloc) and bool(parsed.scheme)
        except:
            return False
    
    def _detect_url_type(self, url):
        """URL íƒ€ì… ê°ì§€"""
        domain = urlparse(url).netloc.lower()
        
        # ìœ íŠœë¸Œ ê°ì§€
        if 'youtube.com' in domain or 'youtu.be' in domain:
            return 'youtube'
        
        # ë‰´ìŠ¤ ì‚¬ì´íŠ¸ ê°ì§€
        news_domains = [
            'naver.com', 'daum.net', 'chosun.com', 'joongang.co.kr',
            'donga.com', 'hani.co.kr', 'khan.co.kr', 'ytn.co.kr',
            'sbs.co.kr', 'mbc.co.kr', 'kbs.co.kr', 'newsis.com',
            'yna.co.kr', 'mk.co.kr', 'mt.co.kr', 'edaily.co.kr',
            'bbc.com', 'cnn.com', 'reuters.com', 'ap.org'
        ]
        
        for news_domain in news_domains:
            if news_domain in domain:
                return 'news'
        
        # ë¸”ë¡œê·¸ í”Œë«í¼ ê°ì§€
        blog_domains = [
            'tistory.com', 'blog.naver.com', 'brunch.co.kr',
            'medium.com', 'wordpress.com', 'blogger.com'
        ]
        
        for blog_domain in blog_domains:
            if blog_domain in domain:
                return 'blog'
        
        return 'website'
    
    def _get_preview_info(self, url):
        """ë¯¸ë¦¬ë³´ê¸° ì •ë³´ ì¶”ì¶œ"""
        try:
            response = self.session.get(url, timeout=15)
            if response.status_code == 200:
                soup = BeautifulSoup(response.content, 'html.parser')
                
                # ì œëª© ì¶”ì¶œ
                title = self._extract_title(soup)
                
                # ì„¤ëª… ì¶”ì¶œ
                description = self._extract_description(soup)
                
                return {
                    'title': title,
                    'description': description
                }
        except:
            pass
        
        return {
            'title': '',
            'description': ''
        }
    
    def _extract_title(self, soup):
        """ì œëª© ì¶”ì¶œ"""
        # 1. og:title ë©”íƒ€ íƒœê·¸
        og_title = soup.find('meta', property='og:title')
        if og_title and og_title.get('content'):
            return og_title['content'].strip()
        
        # 2. title íƒœê·¸
        title_tag = soup.find('title')
        if title_tag:
            return title_tag.get_text().strip()
        
        # 3. h1 íƒœê·¸
        h1_tag = soup.find('h1')
        if h1_tag:
            return h1_tag.get_text().strip()
        
        return ''
    
    def _extract_description(self, soup):
        """ì„¤ëª… ì¶”ì¶œ"""
        # 1. og:description ë©”íƒ€ íƒœê·¸
        og_desc = soup.find('meta', property='og:description')
        if og_desc and og_desc.get('content'):
            return og_desc['content'].strip()
        
        # 2. description ë©”íƒ€ íƒœê·¸
        meta_desc = soup.find('meta', attrs={'name': 'description'})
        if meta_desc and meta_desc.get('content'):
            return meta_desc['content'].strip()
        
        # 3. ì²« ë²ˆì§¸ p íƒœê·¸
        p_tag = soup.find('p')
        if p_tag:
            text = p_tag.get_text().strip()
            if len(text) > 50:
                return text[:200] + '...' if len(text) > 200 else text
        
        return ''

def validate_url_quick(url):
    """ë¹ ë¥¸ URL ìœ íš¨ì„± ê²€ì‚¬"""
    validator = URLValidator()
    return validator.validate_url(url)

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    test_urls = [
        "https://youtu.be/CcTlWxLKR80?si=W1wEtd-_AaPRrQSI",
        "https://news.naver.com/",
        "https://invalid-url"
    ]
    
    validator = URLValidator()
    
    for url in test_urls:
        print(f"\nğŸ” URL í…ŒìŠ¤íŠ¸: {url}")
        result = validator.validate_url(url)
        print(f"âœ… ìœ íš¨ì„±: {'í†µê³¼' if result['valid'] else 'ì‹¤íŒ¨'}")
        print(f"ğŸŒ ì ‘ê·¼ì„±: {'ê°€ëŠ¥' if result['accessible'] else 'ë¶ˆê°€ëŠ¥'}")
        print(f"ğŸ·ï¸ íƒ€ì…: {result['type']}")
        print(f"ğŸ“„ ì œëª©: {result['title']}")
        print(f"ğŸ“ ì„¤ëª…: {result['description']}")
        if result['error']:
            print(f"âŒ ì˜¤ë¥˜: {result['error']}") 